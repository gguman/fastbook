{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a540d0-f484-4cf1-8de4-0dffbb59f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6a28cb-d585-4735-b37d-2034ee3007ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit-recognizer.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!/home/gguser01/.venvs/vfastai/bin/kaggle competitions download -c digit-recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326b9936-590e-456a-bd93-1bb42c92c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, torch, math, os, PIL, torchvision\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fed1da43-0538-49ef-ba32-ac2038165166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu'); device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ace9e5-5ace-4e2f-aac5-c3bbf0c94067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ZipInfo filename='sample_submission.csv' compress_type=deflate file_size=240909 compress_size=62816>,\n",
       " <ZipInfo filename='test.csv' compress_type=deflate file_size=51118296 compress_size=6385439>,\n",
       " <ZipInfo filename='train.csv' compress_type=deflate file_size=76775041 compress_size=9605867>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zf = zipfile.ZipFile('digit-recognizer.zip'); zf.filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5a3ff8-e003-4a43-9731-9a2523ddfec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(zf.open('train.csv'), dtype='float32')\n",
    "test_df = pd.read_csv(zf.open('test.csv'), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf0431f-222f-4148-ae91-56a95353be9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2    1.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3    4.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4    0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "3     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4     0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0       0.0       0.0       0.0       0.0  \n",
       "1       0.0       0.0       0.0       0.0  \n",
       "2       0.0       0.0       0.0       0.0  \n",
       "3       0.0       0.0       0.0       0.0  \n",
       "4       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e55f618-4e7c-404f-b2ad-8ba81c80d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mnist_dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, transforms=None, test=False):\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        self.test = test\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if not self.test:\n",
    "            img = self.data.iloc[idx].iloc[1:].div(255).values.reshape(28, 28, 1)\n",
    "            lbl = train_df.iloc[idx].label\n",
    "        else:\n",
    "            img = self.data.iloc[idx].div(255).values.reshape(28, 28, 1)\n",
    "            lbl = np.empty(0)\n",
    "        \n",
    "        if self.transforms: img = self.transforms(img)\n",
    "\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b0598e9b-73c1-4c0f-8bed-a8bf97a39b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x torch.Size([2, 4]) (4, 1) True\n",
      "y torch.Size([8]) (1,) True\n",
      "w torch.Size([2, 4, 8]) (32, 8, 1) True\n",
      "z torch.Size([2, 2, 8]) (32, 16, 1) False\n",
      "z2 torch.Size([32]) (1,) True\n"
     ]
    }
   ],
   "source": [
    "#https://discuss.pytorch.org/t/whats-the-difference-between-torch-reshape-vs-torch-view/159172\n",
    "#reshape will return a view if possible and will trigger a copy otherwise as explained in the docs 108. If in doubt, you can use reshape if you do not explicitly expect a view of the tensor.\n",
    "#A view points to the same data stored in memory using a changed meta-data such as its shape and stride.\n",
    "x = torch.randn(2, 4); print('x', x.size(), x.stride(), x.is_contiguous())\n",
    "y = x.view(-1); print('y', y.size(), y.stride(), y.is_contiguous())\n",
    "\n",
    "w = torch.randn(2, 4, 8); print('w', w.size(), w.stride(), w.is_contiguous())\n",
    "z = w[:, ::2]; print('z', z.size(), z.stride(), z.is_contiguous())\n",
    "#z1 = z.view(-1) RuntimeError: view size is not compatible with input tensor's size...\n",
    "z2 = z.reshape(-1); print('z2', z2.size(), z2.stride(), z2.is_contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f8e2848b-3b8f-44c5-9c02-98cf966ba125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.7373, 1.0000, 0.3686, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.7490, 0.9804, 0.9922, 0.3647, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4824, 0.9725, 0.9922, 0.6549, 0.0392, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3137, 0.9686, 0.9922, 0.8157, 0.0510, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1137, 0.8118, 0.9922, 0.9216, 0.3020, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2118,\n",
       "          0.8196, 0.9922, 0.9922, 0.3451, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3647, 0.9961,\n",
       "          0.9922, 0.9333, 0.6667, 0.0667, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0902, 0.8235, 0.9961,\n",
       "          0.9922, 0.6235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.8196, 0.9922, 0.9961,\n",
       "          0.9412, 0.3176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1059, 0.9922, 0.9922, 0.9961,\n",
       "          0.0510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0784, 0.8078, 0.9961, 0.9961, 0.7765,\n",
       "          0.0275, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.6588, 0.9922, 0.9922, 0.7686, 0.0275,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0784, 0.7961, 0.9922, 0.9725, 0.2980, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0863, 0.7373, 0.9922, 0.9608, 0.3647, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.4039, 0.9922, 0.9922, 0.7490, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3490, 0.9412, 0.9922, 0.7647, 0.0980, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0588,\n",
       "          0.8627, 0.9922, 0.9922, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3686,\n",
       "          0.9922, 0.9922, 0.9922, 0.3686, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3490,\n",
       "          0.9843, 0.9922, 0.9804, 0.5137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.8392, 0.8549, 0.3725, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(train_df.iloc[0].iloc[1:].div(255).values).view(1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "73263976-5016-4a40-b9f6-e8a0f6118abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_ds = mnist_dataset(\n",
    "    train_df, \n",
    "    transforms=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "    ); len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e2bd6bd6-8041-4983-86fa-fc4a13b97869",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "generator = torch.Generator().manual_seed(random_seed)\n",
    "\n",
    "validation_size = int(len(mnist_ds) * validation_split)\n",
    "train_size = len(mnist_ds) - validation_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "    mnist_ds,\n",
    "    [train_size, validation_size],\n",
    "    generator=generator\n",
    ")\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=shuffle_dataset\n",
    ")\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "b2f92529-a839-4441-809c-270af0fef181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600 8400\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(validation_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "76c7dc3a-7f79-4e26-b967-690a260a19ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n",
      "Data in the batch: tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "val_features, val_labels = next(iter(validation_dataloader))\n",
    "\n",
    "print(f'Feature batch shape: {train_features.size()}')\n",
    "print(f'Labels batch shape: {train_labels.size()}')\n",
    "print(f'Data in the batch: {train_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b87fe90d-2e20-45b2-b393-1a5a54b57da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_features[0].reshape(28, 28, 1), cmap='gray'); train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c2ff06b6-6859-4585-926d-ba8be1d4d8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcBUlEQVR4nO3df2xV9f3H8dcttFeU9naltLd3FCz4A0Olbgi1Ufni2kC7jIgyI0oyWIxMVswAUcMCgrqlDhM0bojbYmAmos5MIJJZg8WW6AoElDD3o6GsGxhomSS9txQpSD/fP4h3XmnBc7m37/b2+Ug+Se85593z9uNJX5x7Tz/1OeecAADoY2nWDQAABicCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACaGWjfwdd3d3Tp69KgyMzPl8/ms2wEAeOScU0dHh0KhkNLSer/P6XcBdPToURUWFlq3AQC4TEeOHNGoUaN63d/v3oLLzMy0bgEAkACX+nmetABat26drr76al1xxRUqLS3Vnj17vlEdb7sBQGq41M/zpATQG2+8oaVLl2rVqlX66KOPVFJSohkzZuj48ePJOB0AYCBySTBlyhRXXV0dfX3u3DkXCoVcTU3NJWvD4bCTxGAwGIwBPsLh8EV/3if8DujMmTPat2+fKioqotvS0tJUUVGhxsbGC47v6upSJBKJGQCA1JfwAPrss8907tw55efnx2zPz89Xa2vrBcfX1NQoEAhEB0/AAcDgYP4U3PLlyxUOh6PjyJEj1i0BAPpAwn8PKDc3V0OGDFFbW1vM9ra2NgWDwQuO9/v98vv9iW4DANDPJfwOKCMjQ5MmTVJdXV10W3d3t+rq6lRWVpbo0wEABqikrISwdOlSzZs3TzfffLOmTJmi559/Xp2dnfrxj3+cjNMBAAagpATQvffeq//+97964okn1Nraqptuukm1tbUXPJgAABi8fM45Z93EV0UiEQUCAes2AACXKRwOKysrq9f95k/BAQAGJwIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhIeACtXr1aPp8vZowfPz7RpwEADHBDk/FNJ0yYoPfee+9/JxmalNMAAAawpCTD0KFDFQwGk/GtAQApIimfAR08eFChUEhjx47V3Llzdfjw4V6P7erqUiQSiRkAgNSX8AAqLS3Vxo0bVVtbq/Xr16ulpUW33367Ojo6ejy+pqZGgUAgOgoLCxPdEgCgH/I551wyT9De3q4xY8Zo7dq1euCBBy7Y39XVpa6urujrSCRCCAFACgiHw8rKyup1f9KfDsjOztZ1112n5ubmHvf7/X75/f5ktwEA6GeS/ntAJ0+e1KFDh1RQUJDsUwEABpCEB9CyZcvU0NCgf//73/rLX/6iu+66S0OGDNF9992X6FMBAAawhL8F9+mnn+q+++7TiRMnNHLkSN12223atWuXRo4cmehTAQAGsKQ/hOBVJBJRIBCwbgP4xiorKz3XXHXVVZ5rfvjDH3qumTNnjucaSeqrHwu9fTZ8MQ8//LDnmnfffddzDS7fpR5CYC04AIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJliMFP3eiBEjPNc888wzcZ3rnnvu8VyTmZnpucbn83muwXmnT5/2XHPXXXfFdS4WMb08LEYKAOiXCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmWA0bfWru3Lmea1588UXPNfGsUJ2KOjs746qrr69PbCMJdMstt3iuyc7OjutcP/jBDzzXsIL2/7AaNgCgXyKAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGBiqHUDGLgef/xxzzWrV6/2XOP3+z3XxCsSiXiu+f3vf++55rnnnvNc09HR4bmmu7vbc40U/yKmXmVkZHiu2b17t+eaESNGeK6RpOrqas81LEb6zXEHBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwASLkULFxcVx1T311FOea9LT0z3XtLe3e67ZunWr5xpJevrppz3X/Otf/4rrXIhvQduSkpIkdNKz8vLyPjvXYMQdEADABAEEADDhOYB27typmTNnKhQKyefzacuWLTH7nXN64oknVFBQoGHDhqmiokIHDx5MVL8AgBThOYA6OztVUlKidevW9bh/zZo1euGFF/TSSy9p9+7duuqqqzRjxgydPn36spsFAKQOzw8hVFVVqaqqqsd9zjk9//zzWrFihe68805J0iuvvKL8/Hxt2bJFc+bMubxuAQApI6GfAbW0tKi1tVUVFRXRbYFAQKWlpWpsbOyxpqurS5FIJGYAAFJfQgOotbVVkpSfnx+zPT8/P7rv62pqahQIBKKjsLAwkS0BAPop86fgli9frnA4HB1HjhyxbgkA0AcSGkDBYFCS1NbWFrO9ra0tuu/r/H6/srKyYgYAIPUlNICKiooUDAZVV1cX3RaJRLR7926VlZUl8lQAgAHO81NwJ0+eVHNzc/R1S0uL9u/fr5ycHI0ePVqLFy/WL37xC1177bUqKirSypUrFQqFNGvWrET2DQAY4DwH0N69e3XHHXdEXy9dulSSNG/ePG3cuFGPPfaYOjs7tWDBArW3t+u2225TbW2trrjiisR1DQAY8HzOOWfdxFdFIhEFAgHrNgaVPXv2xFV38803e66JZ2HRm266yXPN4cOHPdfg8qxYscJzzcqVKz3XxLOgbbw+/PBDzzW33357EjoZmMLh8EU/1zd/Cg4AMDgRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEx4/nMMSD3FxcVx1bGydf8X759BWbVqleeaJUuWeK7py5Wt47F27VrrFlIad0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMsBgp4rZnzx7PNSwsel48C8BOmjTJc82yZcs810jShAkT4qrrr95+++246mpraxPcCb6KOyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmWIwUeuaZZ+Kqe/TRRz3XPPvss55rzpw547kmXjNnzvRcc+WVV3quKSws9FyTnp7uuSYVffHFF55rampq4jrX559/HlcdvhnugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJjwOeecdRNfFYlEFAgErNsYVK655pq46v761796rvH7/XGdK9UcPHjQc82HH37ouWb+/Pmea/pSPAuL3nPPPZ5rtm7d6rkGly8cDisrK6vX/dwBAQBMEEAAABOeA2jnzp2aOXOmQqGQfD6ftmzZErN//vz58vl8MaOysjJR/QIAUoTnAOrs7FRJSYnWrVvX6zGVlZU6duxYdLz22muX1SQAIPV4/ouoVVVVqqqquugxfr9fwWAw7qYAAKkvKZ8B1dfXKy8vT9dff70WLlyoEydO9HpsV1eXIpFIzAAApL6EB1BlZaVeeeUV1dXV6Ve/+pUaGhpUVVWlc+fO9Xh8TU2NAoFAdBQWFia6JQBAP+T5LbhLmTNnTvTrG2+8URMnTtS4ceNUX1+v8vLyC45fvny5li5dGn0diUQIIQAYBJL+GPbYsWOVm5ur5ubmHvf7/X5lZWXFDABA6kt6AH366ac6ceKECgoKkn0qAMAA4vktuJMnT8bczbS0tGj//v3KyclRTk6OnnzySc2ePVvBYFCHDh3SY489pmuuuUYzZsxIaOMAgIHNcwDt3btXd9xxR/T1l5/fzJs3T+vXr9eBAwf0hz/8Qe3t7QqFQpo+fbqefvpp1gADAMTwHEDTpk3TxdYvfffddy+rIfS93j6fu5Sf/OQnnmtWrlzpuWbkyJGea9LT0z3XSLroL1j35tSpU55rfvOb33iu+eUvf+m5pr/77W9/67mGhUVTB2vBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBM+NzFlrY2EIlEFAgErNtAkgwfPtxzzYgRIzzXxLsadrwrg3t19dVXe65pbGz0XJOfn++5Jl4tLS2eayZOnOi5prOz03MNbITD4Yv+lWvugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgYat0ABpeTJ0/2SU1fimdh0draWs81fbmw6BdffOG5ZsGCBZ5rWFh0cOMOCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkWIwW+IiMjw3PNn/70J8811113neeavrRy5UrPNXV1dUnoBKmMOyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmWIwUKSk9PT2uum3btnmu+c53vhPXufrCu+++G1fdunXrEtwJcCHugAAAJgggAIAJTwFUU1OjyZMnKzMzU3l5eZo1a5aamppijjl9+rSqq6s1YsQIDR8+XLNnz1ZbW1tCmwYADHyeAqihoUHV1dXatWuXtm/frrNnz2r69Onq7OyMHrNkyRK9/fbbevPNN9XQ0KCjR4/q7rvvTnjjAICBzdNDCLW1tTGvN27cqLy8PO3bt09Tp05VOBzWyy+/rE2bNul73/ueJGnDhg264YYbtGvXLt1yyy2J6xwAMKBd1mdA4XBYkpSTkyNJ2rdvn86ePauKioroMePHj9fo0aPV2NjY4/fo6upSJBKJGQCA1Bd3AHV3d2vx4sW69dZbVVxcLElqbW1VRkaGsrOzY47Nz89Xa2trj9+npqZGgUAgOgoLC+NtCQAwgMQdQNXV1frkk0/0+uuvX1YDy5cvVzgcjo4jR45c1vcDAAwMcf0i6qJFi7Rt2zbt3LlTo0aNim4PBoM6c+aM2tvbY+6C2traFAwGe/xefr9ffr8/njYAAAOYpzsg55wWLVqkzZs3a8eOHSoqKorZP2nSJKWnp6uuri66rampSYcPH1ZZWVliOgYApARPd0DV1dXatGmTtm7dqszMzOjnOoFAQMOGDVMgENADDzygpUuXKicnR1lZWXr44YdVVlbGE3AAgBieAmj9+vWSpGnTpsVs37Bhg+bPny9Jeu6555SWlqbZs2erq6tLM2bM0IsvvpiQZgEAqcPnnHPWTXxVJBJRIBCwbgP9SDwLi/75z3+O61zl5eVx1fWF1atXe65Zu3ZtXOc6efJkXHXAV4XDYWVlZfW6n7XgAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAm4vqLqEBf+tGPfuS5pi9XtT537pznmpdfftlzTTwrW7OqNfoz7oAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCY8DnnnHUTXxWJRBQIBKzbQJKMGjXKc83f/vY3zzWZmZmea+L1yCOPeK557rnnktAJ0L+Ew2FlZWX1up87IACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACaGWjeAgSstzfu/X9555x3PNX25sOj27ds91/zud79LQidA6uMOCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkWI0XcKioqPNdMmDAhCZ1c6MSJE3HVzZ0713NNZ2dnXOcCBjvugAAAJgggAIAJTwFUU1OjyZMnKzMzU3l5eZo1a5aamppijpk2bZp8Pl/MeOihhxLaNABg4PMUQA0NDaqurtauXbu0fft2nT17VtOnT7/gPfAHH3xQx44di441a9YktGkAwMDn6SGE2tramNcbN25UXl6e9u3bp6lTp0a3X3nllQoGg4npEACQki7rM6BwOCxJysnJidn+6quvKjc3V8XFxVq+fLlOnTrV6/fo6upSJBKJGQCA1Bf3Y9jd3d1avHixbr31VhUXF0e333///RozZoxCoZAOHDigxx9/XE1NTXrrrbd6/D41NTV68skn420DADBA+ZxzLp7ChQsX6p133tEHH3ygUaNG9Xrcjh07VF5erubmZo0bN+6C/V1dXerq6oq+jkQiKiwsjKcl9LHp06d7rvn627jJEu/vAd1www2eaz777LO4zgWkunA4rKysrF73x3UHtGjRIm3btk07d+68aPhIUmlpqST1GkB+v19+vz+eNgAAA5inAHLO6eGHH9bmzZtVX1+voqKiS9bs379fklRQUBBXgwCA1OQpgKqrq7Vp0yZt3bpVmZmZam1tlSQFAgENGzZMhw4d0qZNm/T9739fI0aM0IEDB7RkyRJNnTpVEydOTMp/AABgYPIUQOvXr5d0/pdNv2rDhg2aP3++MjIy9N577+n5559XZ2enCgsLNXv2bK1YsSJhDQMAUoPnt+AuprCwUA0NDZfVEABgcIj7KbhkiUQiCgQC1m0AAC7TpZ6CYzFSAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJvpdADnnrFsAACTApX6e97sA6ujosG4BAJAAl/p57nP97Jaju7tbR48eVWZmpnw+X8y+SCSiwsJCHTlyRFlZWUYd2mMezmMezmMezmMezusP8+CcU0dHh0KhkNLSer/PGdqHPX0jaWlpGjVq1EWPycrKGtQX2JeYh/OYh/OYh/OYh/Os5yEQCFzymH73FhwAYHAggAAAJgZUAPn9fq1atUp+v9+6FVPMw3nMw3nMw3nMw3kDaR763UMIAIDBYUDdAQEAUgcBBAAwQQABAEwQQAAAEwMmgNatW6err75aV1xxhUpLS7Vnzx7rlvrc6tWr5fP5Ysb48eOt20q6nTt3aubMmQqFQvL5fNqyZUvMfuecnnjiCRUUFGjYsGGqqKjQwYMHbZpNokvNw/z58y+4PiorK22aTZKamhpNnjxZmZmZysvL06xZs9TU1BRzzOnTp1VdXa0RI0Zo+PDhmj17ttra2ow6To5vMg/Tpk274Hp46KGHjDru2YAIoDfeeENLly7VqlWr9NFHH6mkpEQzZszQ8ePHrVvrcxMmTNCxY8ei44MPPrBuKek6OztVUlKidevW9bh/zZo1euGFF/TSSy9p9+7duuqqqzRjxgydPn26jztNrkvNgyRVVlbGXB+vvfZaH3aYfA0NDaqurtauXbu0fft2nT17VtOnT1dnZ2f0mCVLlujtt9/Wm2++qYaGBh09elR33323YdeJ903mQZIefPDBmOthzZo1Rh33wg0AU6ZMcdXV1dHX586dc6FQyNXU1Bh21fdWrVrlSkpKrNswJclt3rw5+rq7u9sFg0H37LPPRre1t7c7v9/vXnvtNYMO+8bX58E55+bNm+fuvPNOk36sHD9+3ElyDQ0Nzrnz/+/T09Pdm2++GT3mH//4h5PkGhsbrdpMuq/Pg3PO/d///Z/72c9+ZtfUN9Dv74DOnDmjffv2qaKiIrotLS1NFRUVamxsNOzMxsGDBxUKhTR27FjNnTtXhw8ftm7JVEtLi1pbW2Ouj0AgoNLS0kF5fdTX1ysvL0/XX3+9Fi5cqBMnTli3lFThcFiSlJOTI0nat2+fzp49G3M9jB8/XqNHj07p6+Hr8/ClV199Vbm5uSouLtby5ct16tQpi/Z61e8WI/26zz77TOfOnVN+fn7M9vz8fP3zn/806spGaWmpNm7cqOuvv17Hjh3Tk08+qdtvv12ffPKJMjMzrdsz0draKkk9Xh9f7hssKisrdffdd6uoqEiHDh3Sz3/+c1VVVamxsVFDhgyxbi/huru7tXjxYt16660qLi6WdP56yMjIUHZ2dsyxqXw99DQPknT//fdrzJgxCoVCOnDggB5//HE1NTXprbfeMuw2Vr8PIPxPVVVV9OuJEyeqtLRUY8aM0R//+Ec98MADhp2hP5gzZ0706xtvvFETJ07UuHHjVF9fr/LycsPOkqO6ulqffPLJoPgc9GJ6m4cFCxZEv77xxhtVUFCg8vJyHTp0SOPGjevrNnvU79+Cy83N1ZAhQy54iqWtrU3BYNCoq/4hOztb1113nZqbm61bMfPlNcD1caGxY8cqNzc3Ja+PRYsWadu2bXr//fdj/nxLMBjUmTNn1N7eHnN8ql4Pvc1DT0pLSyWpX10P/T6AMjIyNGnSJNXV1UW3dXd3q66uTmVlZYad2Tt58qQOHTqkgoIC61bMFBUVKRgMxlwfkUhEu3fvHvTXx6effqoTJ06k1PXhnNOiRYu0efNm7dixQ0VFRTH7J02apPT09JjroampSYcPH06p6+FS89CT/fv3S1L/uh6sn4L4Jl5//XXn9/vdxo0b3d///ne3YMECl52d7VpbW61b61OPPPKIq6+vdy0tLe7DDz90FRUVLjc31x0/fty6taTq6OhwH3/8sfv444+dJLd27Vr38ccfu//85z/OOeeeeeYZl52d7bZu3eoOHDjg7rzzTldUVOQ+//xz484T62Lz0NHR4ZYtW+YaGxtdS0uLe++999x3v/tdd+2117rTp09bt54wCxcudIFAwNXX17tjx45Fx6lTp6LHPPTQQ2706NFux44dbu/eva6srMyVlZUZdp14l5qH5uZm99RTT7m9e/e6lpYWt3XrVjd27Fg3depU485jDYgAcs65X//612706NEuIyPDTZkyxe3atcu6pT537733uoKCApeRkeG+/e1vu3vvvdc1Nzdbt5V077//vpN0wZg3b55z7vyj2CtXrnT5+fnO7/e78vJy19TUZNt0ElxsHk6dOuWmT5/uRo4c6dLT092YMWPcgw8+mHL/SOvpv1+S27BhQ/SYzz//3P30pz913/rWt9yVV17p7rrrLnfs2DG7ppPgUvNw+PBhN3XqVJeTk+P8fr+75ppr3KOPPurC4bBt41/Dn2MAAJjo958BAQBSEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABP/D9srAPIHqQ+VAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(val_features[0].reshape(28, 28, 1), cmap='gray'); val_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "62ac739b-77c3-4452-aada-d0283bcdc565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
    "    \n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.long().to(device)\n",
    "            \n",
    "            prediction = model(x)\n",
    "            loss_value = loss(prediction, y)\n",
    "            \n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y)\n",
    "            total_samples += y.shape[0]\n",
    "\n",
    "            loss_accum += loss_value\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_acc = float(correct_samples) / total_samples\n",
    "        val_acc = compute_accuracy(model, val_loader)\n",
    "\n",
    "        print(\"Epoch: %i/%i, Average Loss: %f, Train acc: %f, Val acc: %f\" %\n",
    "            (epoch + 1, num_epochs, ave_loss, train_acc, val_acc)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8ff5ea26-b9f4-47ad-9a41-9eed8771c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    correct_samples, total_samples = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(loader):\n",
    "            x = inputs.to(device)\n",
    "            y = labels.to(device)\n",
    "\n",
    "            output = model(x)\n",
    "            prediction = torch.argmax(output, axis=1)\n",
    "        \n",
    "            correct_samples += torch.sum(prediction == y)\n",
    "            total_samples += y.shape[0]\n",
    "\n",
    "    return correct_samples / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8524d6c-7590-47f2-b293-8e80afce8903",
   "metadata": {},
   "source": [
    "# Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd76e32-3383-458c-982d-5848e5be46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataloader))[0].shape  #torch.Size([64, 1, 28, 28])  \n",
    "torch.nn.Flatten()(next(iter(train_dataloader))[0]).shape    #torch.Size([64, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "3a52b4cc-549a-4765-a193-1d59caf37319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(1 * 28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "model_0 = LinearModel()\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9baa5fa1-b90e-4e66-96aa-8f6cca1d505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Average Loss: 0.407702, Train acc: 0.881667, Val acc: 0.897381\n",
      "Epoch: 2/10, Average Loss: 0.307334, Train acc: 0.911786, Val acc: 0.905357\n",
      "Epoch: 3/10, Average Loss: 0.290246, Train acc: 0.916101, Val acc: 0.909405\n",
      "Epoch: 4/10, Average Loss: 0.280180, Train acc: 0.919970, Val acc: 0.909524\n",
      "Epoch: 5/10, Average Loss: 0.273484, Train acc: 0.922649, Val acc: 0.912143\n",
      "Epoch: 6/10, Average Loss: 0.267967, Train acc: 0.923512, Val acc: 0.910714\n",
      "Epoch: 7/10, Average Loss: 0.263386, Train acc: 0.924762, Val acc: 0.914762\n",
      "Epoch: 8/10, Average Loss: 0.260971, Train acc: 0.924673, Val acc: 0.916191\n",
      "Epoch: 9/10, Average Loss: 0.257996, Train acc: 0.927202, Val acc: 0.918571\n",
      "Epoch: 10/10, Average Loss: 0.255122, Train acc: 0.925714, Val acc: 0.912857\n"
     ]
    }
   ],
   "source": [
    "train_model(model_0, train_dataloader, validation_dataloader, loss, optimizer, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b91883-0949-4cd8-b25b-2ace93b18da8",
   "metadata": {},
   "source": [
    "# Lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "bc0e24f4-b833-4915-884f-318e06f0899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-1\n",
    "wd = 1e-5\n",
    "\n",
    "model_lenet = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, padding=0),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.AvgPool2d(2),\n",
    "    torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, padding=0),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.AvgPool2d(2),\n",
    "\n",
    "    torch.nn.Flatten(),\n",
    "\n",
    "    torch.nn.Linear(256, 140),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(140, 84),\n",
    "    torch.nn.Tanh(),\n",
    "    torch.nn.Linear(84, 10)\n",
    ")\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_lenet.parameters(), lr=lr, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "96b69947-c09c-48a1-9254-2b5427564355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Average Loss: 0.702800, Train acc: 0.792679, Val acc: 0.920119\n",
      "Epoch: 2/10, Average Loss: 0.195082, Train acc: 0.941905, Val acc: 0.952143\n",
      "Epoch: 3/10, Average Loss: 0.117102, Train acc: 0.964167, Val acc: 0.964167\n",
      "Epoch: 4/10, Average Loss: 0.086202, Train acc: 0.973571, Val acc: 0.970833\n",
      "Epoch: 5/10, Average Loss: 0.068949, Train acc: 0.978750, Val acc: 0.974048\n",
      "Epoch: 6/10, Average Loss: 0.057935, Train acc: 0.981815, Val acc: 0.976071\n",
      "Epoch: 7/10, Average Loss: 0.049664, Train acc: 0.984732, Val acc: 0.979524\n",
      "Epoch: 8/10, Average Loss: 0.043979, Train acc: 0.986786, Val acc: 0.978810\n",
      "Epoch: 9/10, Average Loss: 0.039439, Train acc: 0.987619, Val acc: 0.982024\n",
      "Epoch: 10/10, Average Loss: 0.034656, Train acc: 0.989315, Val acc: 0.980238\n"
     ]
    }
   ],
   "source": [
    "train_model(model_lenet, train_dataloader, validation_dataloader, loss, optimizer, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2d5cb1-fa17-4085-b829-4a3f78366fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = mnist_dataset(test_df, linear=False, test=True)\n",
    "test_dataload = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=len(test_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b07b8-a436-46a5-8e24-fd3d4d2151de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = model_lenet(next(iter(test_dataload))).argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da8e851-d28b-4a62-a7c1-b0cabbda5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd9905-0879-45fe-9701-c15391d92292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'ImageId':range(1, len(test_res)+1),\n",
    "        'Label': test_res\n",
    "    }\n",
    ").to_csv('submission_131223_Lenet_0.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95aad3c-889d-4b7f-8b65-07535b62b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_lenet, '1_lenet_0986786.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18391eff-affc-42b4-885d-8d4dfead9842",
   "metadata": {},
   "source": [
    "# Capsule Network\n",
    "https://github.com/gram-ai/capsule-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2152f429-f2b4-4e1c-ad3a-72815f4eb7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"720\"\n",
       "            height=\"405\"\n",
       "            src=\"https://www.youtube.com/embed/pPN8d0E3900\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6836e84510>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.IFrame('https://www.youtube.com/embed/pPN8d0E3900', width=720, height=405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8879e421-29d2-4575-8886-503f03039070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"720\"\n",
       "            height=\"405\"\n",
       "            src=\"https://www.youtube.com/embed/2Kawrd5szHE\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f6836579210>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.IFrame('https://www.youtube.com/embed/2Kawrd5szHE', width=720, height=405)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65e20c95-c9a7-438d-87cb-cbb20e928f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 500\n",
    "NUM_ROUTING_ITERATIONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b529fd5-59a9-4a15-a011-49c0b350f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, dim=1):\n",
    "    transposed_x = x.transpose(dim, len(x.size()) - 1)\n",
    "    softmaxed = torch.nn.functional.softmax(transposed_input.contiguous().view(-1, transposed_input.size(-1)), dim=-1)\n",
    "    return softmaxed_output.view(*transposed_x.size()).transpose(dim, len(Ñ‡.size()) - 1)\n",
    "    \n",
    "class CapsuleLayer(torch.nn.Module):\n",
    "    def __init__(self, num_capsules, num_route_nodes, in_channels, out_channels,\n",
    "                 kernel_size=None, stride=None, num_iterations=NUM_ROUTING_ITERATIONS):\n",
    "        super(CapsuleLayer, self).__init__()\n",
    "\n",
    "        self.num_route_nodes = num_route_nodes\n",
    "        self.num_iterations = num_iterations\n",
    "        self.num_capsules = num_capsules\n",
    "\n",
    "        if num_route_nodes != -1:\n",
    "            self.route_weights = torch.nn.Parameter(\n",
    "                torch.randn(num_capsules, num_route_nodes, in_channels, out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.capsules = torch.nn.ModuleList(\n",
    "                [torch.nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=0) for _ in range(num_capsules)])\n",
    "    \n",
    "    def squash(self, tensor, dim=-1, epsilon=1e-7):\n",
    "        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n",
    "        scale = squared_norm / (1 + squared_norm)\n",
    "        return scale * tensor / torch.sqrt(squared_norm + epsilon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_route_nodes != -1:\n",
    "            priors = x[None, :, :, None, :] @ self.route_weights[:, None, :, :, :]\n",
    "\n",
    "            logits = torch.autograd.Variable(torch.zeros(*priors.size()))    #.cuda()\n",
    "            for i in range(self.num_iterations):\n",
    "                probs = softmax(logits, dim=2)\n",
    "                outputs = self.squash((probs * priors).sum(dim=2, keepdim=True))\n",
    "\n",
    "                if i != self.num_iterations - 1:\n",
    "                    delta_logits = (priors * outputs).sum(dim=-1, keepdim=True)\n",
    "                    logits = logits + delta_logits\n",
    "        else:\n",
    "            outputs = [capsule(x).view(x.size(0), -1, 1) for capsule in self.capsules]\n",
    "            outputs = torch.cat(outputs, dim=-1)\n",
    "            outputs = self.squash(outputs)\n",
    "        return outputs\n",
    "\n",
    "class CapsuleNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsuleNet, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=256, kernel_size=9, stride=1)\n",
    "        self.primary_capsules = CapsuleLayer(num_capsules=8, num_route_nodes=-1, in_channels=256, out_channels=32, kernel_size=9, stride=2)\n",
    "        self.digit_capsules = CapsuleLayer(num_capsules=NUM_CLASSES, num_route_nodes=32*6*6, in_channels=8, out_channels=16)\n",
    "\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16 * NUM_CLASSES, 512),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(1024, 784),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        x = torch.nn.Unflatten(1, (1, 28, 28))(x)\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x, inplace=True)\n",
    "        x = self.primary_capsules(x)\n",
    "        x = self.digit_capsules(x).squeeze().transpose(0, 1)\n",
    "\n",
    "        classes = (x ** 2).sum(dim=-1) ** 0.5\n",
    "        classes = torch.nn.functional.softmax(classes, dim=-1)\n",
    "\n",
    "        if y is None:\n",
    "            # In all batches, get the most active capsule\n",
    "            _, max_length_indices = classes.max(dim=1)\n",
    "            y = torch.autograd.Variable(torch.eye(NUM_CLASSES)).index_select(dim=0, index=max_length_indices.data)\n",
    "            #y = torch.autograd.Variable(torch.eye(NUM_CLASSES)).cuda().index_select(dim=0, index=max_length_indices.data)\n",
    "\n",
    "        reconstructions = self.decoder((x * y[:, :, None]).contiguous().view(x.size(0), -1))\n",
    "\n",
    "        return classes, reconstructions\n",
    "\n",
    "class CapsuleLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CapsuleLoss, self).__init__()\n",
    "        self.reconstruction_loss = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def forward(self, images, labels, classes, reconstructions):\n",
    "        left = torch.nn.functional.relu(0.9 - classes, inplace=True) ** 2\n",
    "        right = torch.nn.functional.relu(classes - 0.1, inplace=True) ** 2\n",
    "\n",
    "        margin_loss = labels * left + 0.5 * (1. - labels) * right\n",
    "        margin_loss = margin_loss.sum()\n",
    "\n",
    "        assert torch.numel(images) == torch.numel(reconstructions)\n",
    "        images = images.view(reconstructions.size()[0], -1)\n",
    "        reconstruction_loss = self.reconstruction_loss(reconstructions, images)\n",
    "\n",
    "        return (margin_loss + 0.0005 * reconstruction_loss) / images.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34272a00-5b53-4b30-a535-b1942de11a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_capsule_model(model, train_loader, val_loader, loss, optimizer, num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        for i_step, (x, y) in enumerate(train_loader):\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = torch.eye(10).index_select(dim=0, index=y.long())\n",
    "            #y = y.long().to(device)\n",
    "            \n",
    "            classes, reconstructions = model(x, y)\n",
    "            loss_value = loss(x, y, classes, reconstructions)\n",
    "            \n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss_accum += loss_value.item()\n",
    "\n",
    "        ave_loss = loss_accum / i_step\n",
    "        print(ave_loss)\n",
    "        #train_acc = float(correct_samples) / total_samples\n",
    "        #val_acc = compute_accuracy(model, val_loader)\n",
    "\n",
    "        #print(\"Epoch: %i/%i, Average Loss: %f, Train acc: %f, Val acc: %f\" %\n",
    "        #    (epoch + 1, num_epochs, ave_loss, train_acc, val_acc)\n",
    "        #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc0b5889-d806-41e8-a0dc-b0b09a57261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_capsule = CapsuleNet()\n",
    "optimizer = torch.optim.Adam(model_capsule.parameters())\n",
    "loss = CapsuleLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "403d982e-4d97-41a1-bda2-184b288b0562",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_capsule_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_capsule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataloader_conv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 20\u001b[0m, in \u001b[0;36mtrain_capsule_model\u001b[0;34m(model, train_loader, val_loader, loss, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m classes, reconstructions \u001b[38;5;241m=\u001b[39m model(x, y)\n\u001b[1;32m     18\u001b[0m loss_value \u001b[38;5;241m=\u001b[39m loss(x, y, classes, reconstructions)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.venvs/vfastai/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venvs/vfastai/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_capsule_model(model_capsule, train_dataloader_conv, validation_dataloader_conv, loss, optimizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9f29446-a5b0-4f18-8b99-2dfb30790903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d811f-743c-4554-a594-d33324558c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fast.ai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
